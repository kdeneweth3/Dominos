{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction and transformation\n",
    "- GET the data from twitter's api\n",
    "- Transform the data to find what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_oauthlib import OAuth1\n",
    "import pprint\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###obtain consumer key/secret and token key/secret from twitter dev site.\n",
    "#consumer key/secret\n",
    "c_key = \"\"\n",
    "c_secret = \"\"\n",
    "\n",
    "#token key/secret\n",
    "key = \"\"\n",
    "secret = \"\"\n",
    "\n",
    "# for printing json and objects in easy-to-read format\n",
    "pp = pprint.PrettyPrinter(indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the search url\n",
    "searchURL_init = 'https://api.twitter.com/1.1/search/tweets.json'\n",
    "auth = OAuth1(c_key, c_secret,key, secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function that takes the JSON data and transforms it into dataframes\n",
    "def append_dataframes(result, data): #[tweetsDf, usersDf]\n",
    "    r = result['statuses']\n",
    "    for i in range(len(r)):\n",
    "        #populate the tweetsDf\n",
    "        userId = r[i]['user']['id_str']\n",
    "        created_at = r[i]['created_at']\n",
    "        tweet_text = r[i]['text']\n",
    "        tweetId = r[i]['id_str']\n",
    "        data[0] = data[0].append(pd.DataFrame(data={'authorId':userId, 'created_at':created_at, 'tweet_text':tweet_text},\n",
    "                                              index=[tweetId]))\n",
    "\n",
    "        #populate the usersDf\n",
    "        if userId not in data[1].index:\n",
    "            name = r[i]['user']['name']\n",
    "            screen_name = r[i]['user']['screen_name']\n",
    "            data[1] = data[1].append(pd.DataFrame(data={'name':name, 'screen_name':screen_name}, index=[userId]))\n",
    "            \n",
    "        #populate the userMentionsDf\n",
    "        all_mentions = r[i]['entities']['user_mentions']\n",
    "        for user in range(len(all_mentions)):\n",
    "            userId_mention = all_mentions[user]['id_str']\n",
    "            name_mention = [all_mentions[user]['name']]\n",
    "            screenName_mention = [all_mentions[user]['screen_name']]\n",
    "            data[2] = data[2].append(pd.DataFrame({'mentions_userId':[userId_mention], 'tweetId':[tweetId]}),\n",
    "                                                   ignore_index=True)\n",
    "            if userId_mention not in data[1].index:\n",
    "                data[1] = data[1].append(pd.DataFrame(data={'name':name_mention, 'screen_name':screenName_mention}, \n",
    "                                                  index=[userId_mention]))\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function that calls the twitter API and handles rate limiting\n",
    "def api_call(dataframes=None, tweetCount=5, raw=True): # dataframes as list\n",
    "    if tweetCount%100.0 == 0:\n",
    "        total_pages = tweetCount/100\n",
    "    else:\n",
    "        total_pages = (tweetCount/100) + 1\n",
    "    if tweetCount<=100:\n",
    "        count = tweetCount\n",
    "    else:\n",
    "        count = 100\n",
    "    params = {\"q\":\"@dominos #easyorder\",\"count\":count, 'result_type':'recent'} #initial parameters\n",
    "    next_results = \"\"\n",
    "    call_log = []\n",
    "    page = 1\n",
    "    for i in range(total_pages):\n",
    "        searchURL = searchURL_init + next_results\n",
    "        response = requests.get(searchURL, auth=auth, params=params)\n",
    "        call_log.append(response.status_code)\n",
    "        result = response.json()\n",
    "        try:\n",
    "            next_results = result['search_metadata']['next_results'] #use twitter's cursor to get the next page of results\n",
    "        except KeyError:\n",
    "            if page != total_pages:\n",
    "                print 'API limit reached... snoozing 16 minutes'\n",
    "                time.sleep(360)\n",
    "                print 'API limit reached... 10 minutes remaining'\n",
    "                time.sleep(300)\n",
    "                print 'API limit reached... 5 minutes remaining'\n",
    "                time.sleep(240)\n",
    "                print 'API limit reached... 1 minutes remaining'\n",
    "                time.sleep(60)\n",
    "                print 'Rockets refueled... here we go.'\n",
    "                continue\n",
    "        if not raw:\n",
    "            dfs = append_dataframes(result, dataframes)\n",
    "        params = None\n",
    "        page += 1\n",
    "        \n",
    "    if not raw:\n",
    "        return dfs, call_log\n",
    "    else:\n",
    "        return result, call_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "What does the dataset look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test, log = api_call(tweetCount=1)\n",
    "print test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#explore the metadata\n",
    "pp.pprint(test['search_metadata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#explore the statuses\n",
    "pp.pprint(test['statuses'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find structure of retweets\n",
    "for status in range(len(test['statuses'])):\n",
    "    amt = test['statuses'][status]['entities']['user_mentions']\n",
    "    if len(amt)>2:\n",
    "        pp.pprint(test['statuses'][status])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create emtpy dataframes\n",
    "tweetsDf = pd.DataFrame(columns=['authorId', 'created_at', 'tweet_text']) \n",
    "usersDf = pd.DataFrame(columns=['name', 'screen_name'])\n",
    "userMentionsDf = pd.DataFrame(columns=['mentions_userId', 'tweetId'])\n",
    "dfList = [tweetsDf, usersDf, userMentionsDf]\n",
    "\n",
    "#Call the api and append data to empty dataframes\n",
    "dataframes, log = api_call(dataframes=dfList, tweetCount=350, raw=False)\n",
    "dataframes[0].index.name = 'tweetId'\n",
    "dataframes[1].index.name = 'userId'\n",
    "print 'tweetsDf: {}\\n{}\\n\\n'.format(dataframes[0].shape, dataframes[0].head())\n",
    "print 'usersDf: {}\\n{}\\n\\n'.format(dataframes[1].shape, dataframes[1].head())\n",
    "print 'userMentionsDf: {}\\n{}\\n\\n'.format(dataframes[2].shape, dataframes[2].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove dataframes from the list\n",
    "tweetsDf = dfList[0]\n",
    "usersDf = dfList[1]\n",
    "userMentionsDf = dfList[2]\n",
    "\n",
    "# find unique tweets to check the api did not duplicate any\n",
    "dupTest = tweetsDf.groupby(tweetsDf.index).first().shape\n",
    "print dupTest\n",
    "print 'There are duplicate tweetIds:', dupTest[0]!=tweetsDf.shape[0]\n",
    "print tweetsDf[tweetsDf.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### mentions dataframe #####\n",
    "# for each tweet show all user mentions\n",
    "data = pd.merge(userMentionsDf, tweetsDf, left_on='tweetId', right_index=True) \n",
    "\n",
    "##### welcome dataframe #####\n",
    "# create welcome dataframe: shows all tweets that welcome a new tweet order signup\n",
    "welcomeDf = data[(data.authorId == '31444922') & (data.mentions_userId != '31444922')]\n",
    "welcomeDf = welcomeDf.rename(columns={'created_at':'welcome_datetime'})\n",
    "\n",
    "# subset for only relevant columns\n",
    "welcomeDf = welcomeDf[['mentions_userId', 'welcome_datetime']]\n",
    "print 'welcomeDf: {}\\n{}\\n\\n'.format(welcomeDf.shape, welcomeDf.head())\n",
    "\n",
    "\n",
    "##### orders dataframe #####\n",
    "# create orders dataframe: show all tweets that ordered a pizza\n",
    "ordersDf = data[(data.authorId != '31444922') & (data.mentions_userId == '31444922')]\n",
    "ordersDf = ordersDf.rename(columns={'created_at':'order_datetime'})\n",
    "ordersDf = ordersDf.drop_duplicates() # for retweets @dominos is mentions 2x and the author 1x, this removes the dups\n",
    "\n",
    "# subset for only the relevant columns and groupby to find the min(orderDate), aka: first order\n",
    "ordersDf = ordersDf[['authorId', 'order_datetime']]\n",
    "ordersDf = ordersDf.groupby('authorId', as_index=False).min()\n",
    "print 'ordersDf: {}\\n{}\\n\\n'.format(ordersDf.shape, ordersDf.head())\n",
    "\n",
    "# create duration dataframe: show the difference in activation time and order time\n",
    "durationDf = pd.merge(welcomeDf, ordersDf, left_on='mentions_userId', right_on='authorId')\n",
    "durationDf['duration_seconds'] = np.NaN\n",
    "\n",
    "for index, row in durationDf.iterrows():\n",
    "    orderDate = datetime.strptime(row[3].replace('+0000 ',''), \"%a %b %d %H:%M:%S %Y\")\n",
    "    welcomeDate = datetime.strptime(row[1].replace('+0000 ',''), \"%a %b %d %H:%M:%S %Y\")\n",
    "    durationDf.loc[index, 'order_datetime'] = orderDate\n",
    "    durationDf.loc[index, 'welcome_datetime'] = welcomeDate\n",
    "    diff = orderDate - welcomeDate\n",
    "    durationDf.loc[index, 'duration_seconds'] = diff.total_seconds()\n",
    "\n",
    "print 'durationDf: {}\\n{}\\n\\n'.format(durationDf.shape, durationDf.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min welcome and order dates\n",
    "welcome_min = durationDf.welcome_datetime.min()\n",
    "order_min = durationDf.order_datetime.min()\n",
    "welcome_max = durationDf.welcome_datetime.max()\n",
    "order_max = durationDf.order_datetime.max()\n",
    "\n",
    "print 'min date:', np.min([welcome_min, order_min])\n",
    "print 'max date:', np.max([welcome_max, order_max])\n",
    "print '\\n'\n",
    "print 'tweet date range:', np.max([welcome_max, order_max]) - np.min([welcome_min, order_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# export the resulting dataframes (Windows)\n",
    "directoryLoc = \"\"\n",
    "welcomeDf.to_csv(directoryLoc + \"\\welcomeDf.csv\", index=False)\n",
    "ordersDf.to_csv(directoryLoc + \"\\ordersDf.csv\", index=False)\n",
    "durationDf.to_csv(directoryLoc + \"\\durationDf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS\n",
    "\n",
    "\n",
    "## Contents\n",
    "### 1. Dataset structure\n",
    "- What does the dataset look like?\n",
    "\n",
    "### 2. Results (questions)\n",
    "1. How many customers actually place an order within 6 days after signing up for Tweet Ordering?\n",
    "2. What is the median time difference between when a customer signs up Tweet Ordering and when they place their first order with Tweet Ordering? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "### Conversion rate: who actually ordered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Total new Tweet Ordering signups: {}'.format(len(welcomeDf))\n",
    "print 'Total first time orders (only those from the previous total): {}'.format(len(durationDf))\n",
    "conversion = round((len(durationDf)/float(len(welcomeDf))*100),2)\n",
    "print 'Conversion rate: {}%\\n'.format(conversion)\n",
    "print '##### CONCLUSION #####'\n",
    "print 'About {}% of customers that signed up for Tweet Ordering in the past 6 days placed an order with the same time period.'\\\n",
    "        .format(conversion)\n",
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return '{p:.2f}%  ({v:d})'.format(p=pct,v=val)\n",
    "    return my_autopct\n",
    "\n",
    "labels = 'Activations', 'Placed first order'\n",
    "values = [len(welcomeDf), float(len(durationDf))]\n",
    "explode = (0, 0.35)  # display the orders prominently\n",
    "plt.subplots()\n",
    "patches, texts, autotexts = plt.pie(sizes, explode=explode, labels=labels, autopct=make_autopct(values), startangle=0)\n",
    "plt.axis('equal', pickradius=30)  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
